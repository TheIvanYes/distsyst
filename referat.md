# Реферат по статье "Bigtable: A Distributed Storage System for Structured Data"

[статья](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)

## Вступление

Bigtable - это распределенная система хранения для управления данными в Google, построенная на основе GFS (Google File System). Bigtable предназначен для надежного масштабирования до петабайтов данных и тысяч машин. Разработчики добились нескольких целей: 
- широкая применимость
- масштабируемость
- высокая производительность 
- высокая доступность. 

Во многом Bigtable напоминает типичные базы данных: с ними она разделяет множество стратегий реализации. Параллельные базы данных и базы данных в оперативной памяти также достигли масштабируемости и высокая производительности, но Bigtable предоставляет немного другой интерфейс. Она не поддерживает полную реляционную модель данных, вместо этого это предоставляет клиентам простую модель данных, которая поддерживает динамический контроль над расположением и форматом данных, а также позволяет клиентам решать свойства локальности данных, представленных в хранилище. Данные индексируются с использованием имен строк (rows) и столбцов (columns), которые могут быть произвольными строками (string). Данные обрабатываются в виде неинтерпретированных строк. Параметры схемы Bigtable позволяют клиентам контролировать, следует ли обслуживать данные из памяти или с диска.

## Модель

Bigtable — это разреженный, распределенный, многомерный отсортированный словарь. Словарь индексируется именем строки, именем столбца и временной меткой, каждое значение словаря - это неинтерпретируемый массив байтов. Получается такой кортеж:


`(row: string, column: string, time: int64) -> string`

### Строки (rows)

Ключи строк в таблице представляют собой произвольные строки, каждое чтение или запись данных для одной строки является атомарным (независимо от количества столбцов, которые читаются или в которые пишется информация за операцию). Bigtable хранит данные в лексикографическом порядке (сортировка по строкам). Диапазон строк для таблицы динамически секционируется. Диапазон называется tablet, он является единицей распределения и балансировки нагрузки. В результате, чтение диапозона строк эффективно, клиенты могут использовать это свойство, выбирая свои строки так, чтобы они получили место для эффективного доступа к своим данным. Пример: допустим страницы в одном домене сгруппированы в смежные ряды путем реверса компоненты имени хоста URL-адресов. Допустим, мы хотим положить такой URL - maps.google.com/index.html, тогда строка у нас становится такой - com.google.maps/index.html. И тогда, сохранение страниц с одинаковым доменом повышает эффективность работы, поскольку лежат они теперь рядом.

### Столбцы (columns)

Ключи столбцов сгруппированы в наборы, называемые семействами столбцов, которые образуют базовую единицу управления доступом. Все данные, которые хранятся в семействе столбцов, как правило, одного типа. Примером семейства столбцов для веб-таблицы является язык, на котором была написана веб-страница. Мы используем только один ключ столбца в языковой семье, в котором хранится идентификатор языка каждой веб-страницы. 

### Временная метка (timestamp)

Каждая ячейка в Bigtable может содержать несколько версий одних и тех же данных, эти версии индексируются по отметке времени. Временные метки Bigtable представляют собой 64-битные целые числа. Они могут быть назначены Bigtable, и в этом случае они представляют собой настоящее время в микросекундах или явно назначаться клиентскими приложениями. Версии ячейки хранятся в порядке убывания метки времени, так что самые последние версии могут быть прочитаны первыми. Есть свой сборщик мусора версий ячеек, клиент может указать, что нужно поддерживать только n последних версий ячейки (или указывать временной промежуток, дольше которого ячейки храниться не будут).

## Реализация

Реализация Bigtable состоит из трех основных компонентов: библиотеки, связанной с каждым клиентом, одного главного сервера (мастер-сервер) и множества tablet-серверов. Tablet-серверы могут динамически добавляться (или удаляться) из кластера для адаптации к изменениям рабочих нагрузок. Главный сервер отвечает за назначение tablet-ов tablet-серверу, добавление и истечение срока действия tablet-серверов, балансировку нагрузки tablet-серверов и сборку мусора в GFS. Также он обрабатывает изменение схемы таблицы, к примеру, создание семейства таблиц и столбцов. Каждый tablet-сервер управляет набором tablet-ов - обрабатывает чтение и запись, запросы к tablet-ам, которые он загрузил, а также разбивает tablet-ы, которые стали слишком большими. Как и во многих распределенных системах хранения с одним главным сервером, клиентские данные не проходят через главный сервер: клиенты взаимодействуют напрямую с tablet-серверами для чтения/записи, поэтому, главный сервер не особо загружен.


Кластер хранит несколько таблиц, каждая состоит из набора tablet-ов, и каждый tablet содержит данные, связанные с диапазоном строк. Изначально каждая таблица состоит всего из одного tablet-a. По мере роста таблицы, она начинает разбиваться автоматически на tablet-ы.


Для хранения местоположения tablet-а используется трехуровневая структура, напоминающая B+ дерево, использующееся во многих базах данных.

![bplus](https://github.com/TheIvanYes/distsyst/blob/main/bplus.png)

В Chubby file (Chubby - менеджер локов) на картинке хранится местоположение корневого tablet-а. Он в свою очередь указывает на все tablet-ы в мета-файле, в котором уже указаны локации пользовательских таблиц. 


Каждый tablet приписан к одному tablet-серверу в каждый момент времени. Главный сервер, как я написал выше, занимается assign-ом tablet-ов к tablet-серверам, в том числе, он контроллирует unassigned tablet-ы. Для таких tablet-ов он ищет tablet-сервер со свободным местом, туда он его и assign-ит. Если tablet-сервер по каким-то причинам умирает, то перед смертью он пытается отпустить лок (в том числе, и для этого используется Chubby), для того, чтобы главный сервер смог сделать reassign его tablet-ов. В целом, главный сервер занимается мониторингом таких ситуаций, он перепроверяет директорию с локами и переспрашивает у tablet-ов, все ли нормально с ними и с их tablet-ами и при каких-то проблемах занимается перераспределением tablet-ов между серверами. Если происходит какое-то нарушение коннекта между главным сервером и Chubby, то главный сервер самоуничтожается, однако это никаким образом не влияет на распределение tablet-ов по tablet-серверам.

Единственное, чем не занимается главный сервер - сплитом tablet-ов и объединением в один большой. Этим занимаются непосредственно tablet-сервера, предварительно делая коммит в мета-файл.


Tablet-ы персистентны, вся информация о них хранится в GFS, более новые коммиты хранятся в специальном буфере - называется memtable, более старые лежат как последовательность SSTables (гугловый формат хранения таблиц). Если tablet-сервер хочет восстановить какой-то tablet, он обращается в мета-файл, из которого достает необходимую информацию с местом коммита нужного tablet-а.

## Бенчмарки

![bench](https://github.com/TheIvanYes/distsyst/blob/main/graphik.png)

Таблица показывает число операций в секунду для одного tablet-а, график показывает общее число операций разного типа за одну секунду. 

## Мнение

На момент написания статьи, авторы предлагали некоторые улучшения для Bigtable (по типу использования фильтра Блума или разных компрессий таблиц), но сейчас BigTable очень сильно разрослась, она используется в Google Maps, Google Earth, YouTube, Google Analytics - вне всяких сомнений, она отточена до совершенства, учитывая то, какими продуктами она используется. Меня впечатлило то, как люди придумали свою СУБД для решения своих же проблем, и я никогда не задумывался, насколько сложно создать готовое решение, которым люди (в том числе и я) будут пользоваться как привычным инструментом. При всем этом, само устройство BigTable мне не показалось очень сложным, статья прекрасно и понятно его описывает.
